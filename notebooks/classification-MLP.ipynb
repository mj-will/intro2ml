{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Classification - Multilayer Perception\n",
    "\n",
    "Multilayer perceptrons (MLP) are one of the simplest neural networks that can be applied to a problem. They use only the core building blocks of neural networks: simple neurons.\n",
    "\n",
    "This notebook outlines how to setup a simple MLP (also known as fully-connected networks) and apply it to the MNIST dataset which is series of handwritten digits from zero to nine.\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/mj-will/intro2ml/blob/master/classification-MLP.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports\n",
    "\n",
    "[Keras](https://keras.io/) is now part of [Tensorflow](https://www.tensorflow.org) and all imports with include tensorflow. There are lots of examples of how to use different elements of Keras on its [tensorflow page](https://www.tensorflow.org/guide/keras)\n",
    "\n",
    "Below are the imports that are needed for this example, each will be explained when used, so don't worry about them right now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "Neural networks rely on data to learn and in this example we'll be looking at the MNIST dataset.\n",
    "\n",
    "MNIST is a handwritten digit database with a training set of 60,000 examples and a test set of 10,000 examples. The images are all 28x28 and greyscale. The testing data will be used to validate the network's peformance once it has been trained.\n",
    "\n",
    "It is available [here](http://yann.lecun.com/exdb/mnist/), but is included in Keras and will automatically download."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# load data using the imp\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's common practice to refer to the input data as \"x\" and the output as \"y\" as we'll be following that convention here.\n",
    "\n",
    "Let's have a look at some of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 9 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axs = plt.subplots(3,3)\n",
    "axs = axs.ravel()\n",
    "for i in range(len(axs)):\n",
    "    axs[i].imshow(x_train[i].reshape(28,28), cmap='gray')\n",
    "    axs[i].set_xticks([])\n",
    "    axs[i].set_yticks([])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, the 'x' arrays are the images and the 'y' arrays are the labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### General parameters\n",
    "\n",
    "We need to define some general parameters for networks we're going to use:\n",
    "* Batchsize: refers to the number of images/samples passed to the network in a single instance of training\n",
    "* Number of classes: refers to the number of possible classes in the data, in this case 10 since there a 10 different digits (0-9)\n",
    "* Epochs: refers to the number of times the network will train on the complete dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128    # number of images passed each iteration of training\n",
    "num_classes = 10    # digits 0 to 9, so 10 classes\n",
    "epochs = 20         # number of full passes of the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP\n",
    "\n",
    "This example uses a simple deep neural net (more than 1 layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For an MLP the data needs to be parsed as 1D array, rather than a 2D image. \n",
    "\n",
    "So, the data is reshaped according to the number of samples (60,000 or 10,000) and the size of the image 784 (28x28).\n",
    "\n",
    "The data is then normalized (0,255) to (0,1)nsince neural networks will learn quicker if the data is normalised. This is not to say it's impossible to train a network without normalised data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000 training samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "# reshape data\n",
    "x_train = x_train.reshape(60000, 784)\n",
    "x_test = x_test.reshape(10000, 784)\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "# normalize data\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "print(x_train.shape[0], 'training samples')\n",
    "print(x_test.shape[0], 'test samples')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As is the content of the labels vectors looks something like this:\n",
    "```\n",
    "array([7, 2, 1, ..., 4, 5, 6], dtype=uint8)\n",
    "```\n",
    "The NN expects them labels as binary class matrix instead, i.e. a matrix with a 1 in the position that corresponds to the given class. This is clearer with an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert class vectors to binary class matrices\n",
    "# use built-in keras utilties to do this\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the label for each image looks like this:\n",
    "```\n",
    "array([0., 0., 0., 0., 0., 0., 0., 1., 0., 0.], dtype=float32)\n",
    "```\n",
    "Notice that in the previous array the first digit was a 7. In the array that now corresponds to this values the 8th position is 1, corresponding to the class \"7\" since we're including 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Model\n",
    "\n",
    "We now need to construct the neural network that we're going to training to classify the digits.\n",
    "\n",
    "We start by defining the type of keras model. In this case we're using ```Sequential```. When using this type of model any layers we add are assumed to directly follow from the previous one. The other type is ```Model``` which you can read about [here](https://keras.io/models/model/).\n",
    "\n",
    "We then add the input layer. In this case we're going to use a ```Dense``` layer, i.e. a simple fully connected layer. We need to specify the number of neurons (or nodes), the [activation function](https://en.wikipedia.org/wiki/Activation_function) and the shape of the input with keyword argument ```input_shape```.\n",
    "\n",
    "We then add another dense layer but this time we don't need to specify the input shape.\n",
    "\n",
    "Finally we the output layer. Since this is a classifcation task we want the network to predict one of the ten classes, so we use ten neurons. As for the activation function, we use a [softmax function](https://en.wikipedia.org/wiki/Softmax_function) since this ensures the sum of all the output is one, so they can be thought of as a sort of probability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()    # define the type of keras model\n",
    "# add first layer with relu activation\n",
    "model.add(Dense(512, activation='relu', input_shape=(784,)))\n",
    "# add another layer\n",
    "model.add(Dense(512, activation='relu'))\n",
    "# add the output layer with softmax actiavtion for classication\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "# print a summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model then needs to be compiled. It's at this stage that we specify the loss function, optimiser and metrics.\n",
    "\n",
    "#### Loss function\n",
    "\n",
    "$\\text{MSE} = \\frac{1}{N} (\\bar{y} - y)^{2}$\n",
    "\n",
    "\n",
    "#### Optimiser\n",
    "\n",
    "#### Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile the model\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=Adam(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 9s 156us/sample - loss: 0.2180 - accuracy: 0.9348 - val_loss: 0.1008 - val_accuracy: 0.9678\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 8s 136us/sample - loss: 0.0795 - accuracy: 0.9756 - val_loss: 0.0849 - val_accuracy: 0.9734\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 8s 134us/sample - loss: 0.0492 - accuracy: 0.9840 - val_loss: 0.0724 - val_accuracy: 0.9783\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 8s 136us/sample - loss: 0.0350 - accuracy: 0.9890 - val_loss: 0.0776 - val_accuracy: 0.9784\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 9s 150us/sample - loss: 0.0269 - accuracy: 0.9910 - val_loss: 0.0607 - val_accuracy: 0.9839\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 7s 125us/sample - loss: 0.0206 - accuracy: 0.9928 - val_loss: 0.0719 - val_accuracy: 0.9806\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 8s 132us/sample - loss: 0.0189 - accuracy: 0.9936 - val_loss: 0.0710 - val_accuracy: 0.9812\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 7s 125us/sample - loss: 0.0172 - accuracy: 0.9941 - val_loss: 0.0792 - val_accuracy: 0.9803\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 8s 128us/sample - loss: 0.0119 - accuracy: 0.9962 - val_loss: 0.0808 - val_accuracy: 0.9800\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 8s 126us/sample - loss: 0.0102 - accuracy: 0.9965 - val_loss: 0.0836 - val_accuracy: 0.9815\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 7s 117us/sample - loss: 0.0141 - accuracy: 0.9952 - val_loss: 0.0882 - val_accuracy: 0.9801\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 8s 134us/sample - loss: 0.0139 - accuracy: 0.9955 - val_loss: 0.0764 - val_accuracy: 0.9828\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 8s 138us/sample - loss: 0.0093 - accuracy: 0.9968 - val_loss: 0.0824 - val_accuracy: 0.9819\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 8s 132us/sample - loss: 0.0090 - accuracy: 0.9971 - val_loss: 0.0911 - val_accuracy: 0.9817\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 8s 126us/sample - loss: 0.0119 - accuracy: 0.9961 - val_loss: 0.0946 - val_accuracy: 0.9800\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 8s 127us/sample - loss: 0.0071 - accuracy: 0.9976 - val_loss: 0.0997 - val_accuracy: 0.9824\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 8s 131us/sample - loss: 0.0100 - accuracy: 0.9968 - val_loss: 0.1009 - val_accuracy: 0.9798\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 8s 139us/sample - loss: 0.0043 - accuracy: 0.9987 - val_loss: 0.0960 - val_accuracy: 0.9821\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 8s 129us/sample - loss: 0.0071 - accuracy: 0.9978 - val_loss: 0.1062 - val_accuracy: 0.9805\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 7s 125us/sample - loss: 0.0103 - accuracy: 0.9968 - val_loss: 0.0929 - val_accuracy: 0.9829\n",
      "Test loss: 0.09291122905413111\n",
      "Test accuracy: 0.9829\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_data=(x_test, y_test))\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tf)",
   "language": "python",
   "name": "tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
